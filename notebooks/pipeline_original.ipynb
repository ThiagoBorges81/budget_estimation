{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE WORKFLOW AND FUNCTIONS FOR PIPELINE USE\n",
    "\n",
    "# -1 - TIME ATTRIBUTES\n",
    "# Step -1; Engineer time attributes\n",
    "def time_attr(df):\n",
    "    \"\"\"\n",
    "    Extracts time-based attributes from a DataFrame containing a 'date' column.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame containing a 'date' column from which time-based attributes\n",
    "        will be extracted.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with additional time-based attributes including 'year', 'month',\n",
    "        'day', 'week_of_year', and 'year_week'.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    This function extracts various time-based attributes from a 'date' column in the\n",
    "    input DataFrame, including year, month, day, week of the year, and year-week.\n",
    "    The 'date' column is assumed to be in datetime format.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    # Call the function to extract time-based attributes from the DataFrame df\n",
    "    df_with_time_attrs = time_attr(df)\n",
    "    \"\"\"\n",
    "    #Ensure th date variable is is proper format:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # year\n",
    "    df['year'] = df['date'].dt.year\n",
    "\n",
    "    # month\n",
    "    df['month'] = df['date'].dt.month\n",
    "\n",
    "    # day\n",
    "    df['day'] = df['date'].dt.day\n",
    "\n",
    "    # week of year\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "\n",
    "    # year week\n",
    "    df['year_week'] = df['date'].dt.strftime( '%Y-%W' )\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Step 2: Wrap your custom function using FunctionTransformer\n",
    "time_attr_transformer = FunctionTransformer(time_attr)\n",
    "\n",
    "# 0 - INPUT MISSING DATA USING kNN IMPUTER\n",
    "\n",
    "# Step 0: Define your custom function\n",
    "def data_imputer(df):\n",
    "    \"\"\"\n",
    "    Imputes missing values in specified columns of a DataFrame using KNNImputer.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame containing columns with missing values to be imputed.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with missing values imputed using KNNImputer.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    This function scans the variables to check whether they have missing values from >0 to <10%. \n",
    "    Then, it replaces missing values in the specified columns of the input DataFrame\n",
    "    using KNNImputer from the scikit-learn library. It imputes missing values based on\n",
    "    the k-nearest neighbors of the data points with missing values. The number of neighbors\n",
    "    used for imputation is set to 5 by default.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    # Import required libraries\n",
    "    from sklearn.impute import KNNImputer\n",
    "    \n",
    "    # Call the function to impute missing values in the DataFrame df\n",
    "    df_imputed = data_imputer(df)\n",
    "    \"\"\"\n",
    "    # Calculate the proportion of missing values for each column\n",
    "    missing_proportions = df.isna().sum() / df.shape[0] * 100\n",
    "\n",
    "    # Initialize an empty list to store column names with more than 10% missing values\n",
    "    columns_with_missing = []\n",
    "\n",
    "    # Iterate over each column's missing proportion\n",
    "    for column, proportion in missing_proportions.items():\n",
    "        if proportion > 10:\n",
    "            # Drop column with moe than 10% missing\n",
    "            df.drop(column, axis=1, inplace=True)\n",
    "        elif 0 < proportion < 10:\n",
    "            columns_with_missing.append(column)\n",
    "\n",
    "    # Initialize KNNImputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    # Impute missing values\n",
    "    df[columns_with_missing] = imputer.fit_transform(df[columns_with_missing])\n",
    "\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Step 2: Wrap your custom function using FunctionTransformer\n",
    "data_imputer_transformer = FunctionTransformer(data_imputer)\n",
    "\n",
    "# 1 - FORMATTING THE CATEGORICAL VARIABLES\n",
    "\n",
    "# Step 1: Define your custom function\n",
    "def cat_format(df):\n",
    "    \"\"\"\n",
    "    Formats categorical variables in the given DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame containing categorical variables.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The DataFrame with formatted categorical variables.\n",
    "\n",
    "    Example:\n",
    "        df = cat_format(df)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Fix data type\n",
    "    df['competition_distance'] = df['competition_distance'].astype(int)\n",
    "    # df['competition_open_since_month'] = df['competition_open_since_month'].astype(int)\n",
    "    # df['competition_open_since_year'] = df['competition_open_since_year'].astype(int)\n",
    "\n",
    "    # competition since\n",
    "    ## Formatting the full date for the competition since\n",
    "    # df['competition_since'] = df.apply( lambda x: int(datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'],day=1 ), axis=1 ))\n",
    "\n",
    "    ## Calculate the difference between the recorded selling date and the competition open since date\n",
    "    # df['competition_time_month'] = ( ( df['date'] - df['competition_since'] )/30 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "    # promo since\n",
    "    # df['promo_since'] = df['promo2_since_year'].astype( str ) + '-' + df['promo2_since_week'].astype( str )\n",
    "    # df['promo_since'] = df['promo_since'].apply( lambda x: datetime.strptime( x + '-1', '%Y-%W-%w' ) - timedelta( days=7 ) )\n",
    "    # df['promo_time_week'] = ( ( df['date'] - df['promo_since'] )/7 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "    # # assortment\n",
    "    df['assortment'] = df['assortment'].apply( lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
    "\n",
    "    # # state holiday\n",
    "    df['state_holiday'] = df['state_holiday'].apply( lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Wrap your custom function using FunctionTransformer\n",
    "cat_format_transformer = FunctionTransformer(cat_format)\n",
    "\n",
    "\n",
    "# 2 - RESCALING\n",
    "def rescaling_vars(df):\n",
    "    \"\"\"\n",
    "    Rescales numerical variables in the given DataFrame using RobustScaler and MinMaxScaler.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame containing numerical variables.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The DataFrame with rescaled numerical variables.\n",
    "\n",
    "    Example:\n",
    "        df = rescaling_vars(df)\n",
    "    \"\"\"\n",
    "    rs = RobustScaler() # rescaling the variable\n",
    "    mms = MinMaxScaler()\n",
    "\n",
    "    # # competition distance\n",
    "    # df['competition_distance'] = rs.fit_transform( df[['competition_distance']].values )\n",
    "\n",
    "    # # competition time month\n",
    "    # df['competition_time_month'] = rs.fit_transform( df[['competition_time_month']].values )\n",
    "\n",
    "    # # promo time week\n",
    "    # df['promo_time_week'] = mms.fit_transform( df[['promo_time_week']].values )\n",
    "\n",
    "    # # year\n",
    "    df['year'] = mms.fit_transform( df[['year']].values )\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Step 2: Wrap your custom function using FunctionTransformer\n",
    "rescaling_vars_transformer = FunctionTransformer(rescaling_vars)\n",
    "\n",
    "# 3 - TRANSFORMATION:ENCODING\n",
    "\n",
    "def encode_vars(df):\n",
    "    \"\"\"\n",
    "    Encodes categorical variables in the given DataFrame using different techniques.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame containing categorical variables.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The DataFrame with encoded variables.\n",
    "\n",
    "    Example:\n",
    "        df = encode_vars(df)\n",
    "    \"\"\"\n",
    "\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # state_holiday - One Hot Encoding\n",
    "    df = pd.get_dummies( df, prefix=['state_holiday'], columns = ['state_holiday'] )\n",
    "\n",
    "    # store_type - Label Encoding\n",
    "    df['store_type'] = le.fit_transform( df['store_type'] )\n",
    "    \n",
    "    # assortment - Ordinal Encoding\n",
    "    df['assortment_encoded'] = le.fit_transform(df['assortment'])\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Step 2: Wrap your custom function using FunctionTransformer\n",
    "encode_vars_transformer = FunctionTransformer(encode_vars)\n",
    "\n",
    "# 4 - LOG-TRANSFORM RESPONSE VARIABLE\n",
    "def log_trf_var(df):\n",
    "    \"\"\"\n",
    "    Applies a natural logarithm transformation (log1p) to the 'sales' column in the given DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame containing the 'sales' column.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The DataFrame with the transformed 'sales' column.\n",
    "\n",
    "    Example:\n",
    "        df = log_trf_var(df)\n",
    "    \"\"\"\n",
    "    df['sales'] = np.log1p(df['sales'])\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Step 2: Wrap your custom function using FunctionTransformer\n",
    "log_trf_var_transformer = FunctionTransformer(log_trf_var)\n",
    "\n",
    "# 5 - NATURE TRANSFORMATION\n",
    "def nature_transf_vars(df):\n",
    "    \"\"\"\n",
    "    Apply trigonometric transformations to date-related columns in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Input DataFrame containing columns 'day_of_week',\n",
    "                              'month', 'day', and 'week_of_year'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Transformed DataFrame with additional columns:\n",
    "            - 'day_of_week_sin' and 'day_of_week_cos': Sine and cosine of day of week.\n",
    "            - 'month_sin' and 'month_cos': Sine and cosine of month.\n",
    "            - 'day_sin' and 'day_cos': Sine and cosine of day.\n",
    "            - 'week_of_year_sin' and 'week_of_year_cos': Sine and cosine of week of year.\n",
    "    \"\"\"\n",
    "    # day of week\n",
    "    df['day_of_week_sin'] = df['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "    df['day_of_week_cos'] = df['day_of_week'].apply( lambda x: np.cos( x * ( 2. * np.pi/7 ) ) )\n",
    "\n",
    "    # month\n",
    "    df['month_sin'] = df['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "    df['month_cos'] = df['month'].apply( lambda x: np.cos( x * ( 2. * np.pi/12 ) ) )\n",
    "\n",
    "    # day \n",
    "    df['day_sin'] = df['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "    df['day_cos'] = df['day'].apply( lambda x: np.cos( x * ( 2. * np.pi/30 ) ) )\n",
    "\n",
    "    # week of year\n",
    "    def weeks_in_year(year):\n",
    "        if year % 4 == 0 and (year % 100 != 0 or year % 400 == 0):\n",
    "            \n",
    "            return 53  # Leap year\n",
    "        else:\n",
    "            return 52  # Non-leap year\n",
    "        \n",
    "    df['week_of_year_sin'] = df['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/weeks_in_year(x) ) ) )\n",
    "    df['week_of_year_cos'] = df['week_of_year'].apply( lambda x: np.cos( x * ( 2. * np.pi/weeks_in_year(x) ) ) )\n",
    "\n",
    "    # df['week_of_year'] = df['week_of_year'].apply(lambda x: datetime.strptime(x,\"%Y-%W\"))\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "# Step 2: Wrap your custom function using FunctionTransformer\n",
    "nature_transf_vars_transformer = FunctionTransformer(nature_transf_vars)\n",
    "\n",
    "\n",
    "# Custom transformer for Boruta feature selection\n",
    "class BorutaFeatureSelector:\n",
    "    def __init__(self,estimator):\n",
    "        self.boruta = BorutaPy(estimator=estimator)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.boruta.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.boruta.support_]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('time_attr', time_attr_transformer),\n",
    "    ('data_imputer', data_imputer_transformer),\n",
    "    ('cat_format', cat_format_transformer),\n",
    "    ('rescaling_vars', rescaling_vars_transformer),\n",
    "    ('encode_vars', encode_vars_transformer),\n",
    "    ('log_trf_var', log_trf_var_transformer),\n",
    "    ('nature_transf_vars', nature_transf_vars_transformer),\n",
    "    ('boruta', BorutaFeatureSelector(estimator=RandomForestRegressor(n_jobs=-1))),  # Run Boruta once\n",
    "    ('model_lr', LinearRegression())\n",
    "])\n",
    "\n",
    "# Time series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Perform cross-validation on the entire training data\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Evaluate the mean cross-validation score\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "print(f\"Mean Cross-Validation Accuracy: {mean_cv_score:.4f}\")\n",
    "\n",
    "# Train the final model on the entire training data\n",
    "final_model = pipeline.named_steps['model_lr']\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Transform validation/test data\n",
    "X_val_selected = pipeline.transform(X_val)\n",
    "X_test_selected = pipeline.transform(X_test)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "test_accuracy = final_model.score(X_test_selected, y_test)\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_prod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
